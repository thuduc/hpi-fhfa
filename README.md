## FHFA's Repeat-Sales Aggregation Index Model

This proof-of-concept (POC) demonstrates the use of Claude Code (an agentic coding tool from Anthropic: https://www.anthropic.com/claude-code) to develop and train a model, using FHFA's Repeat-Sales Aggregation Index Model white paper: https://www.fhfa.gov/document/wp2101.pdf (saved as hpi-fhfa-whitepaper.pdf)

#### Development Process: 
* Step 1 - use a reasoning LLM that's able to ingest the model white paper and generate a Product Requirements Document (PRD). A PRD is a requirements specification in markdown format. We used Google Gemini 2.5 Pro for our reasoning LLM. We could have used either OpenAI's ChatGPT o3 (advanded reasoning) or Claude Opus 4. The file hpi_fhfa_prd.md stores the PRD generated by Gemini 2.5 Pro.
* Step 2 - feed this PRD to a coding LLM and request it to generate an implementation plan. We use Claude Code (as the client coding tool that uses Claude Opus 4 LLM) to generate this implementation plan. Claude Opus 4 is known to be the most advanded LLM for coding tasks (compared to ChatGPT o4-mini-high and Gemini 2.5 Pro). The file hpi_fhfa_impl_plan.md stores the implementation plan generated by Clause Code.
* Step 3 - request Claude Code (using Clause Opus 4 LLM) to use the implementation plan hpi_fhfa_impl_plan.md to: 1) scaffold the project; 2) implement all necessary model code and support code; 3) create both unit tests and integration tests (with > 80% of code coverage), including the generation of sample data used for model training and testing. Claude Code was also instructed to iterate/work until all test suites are passing. Claude Code was asked to generate 3 implementations, each leveraging a different tech stack:
  * Python and pandas using statsmodel/scikit-Learn
  * Python and polars
  * Python and pyspark

The 3 implementations took Claude Code about 8 hours to complete (running just 1 agent):
* The Python/pandas stack took about 1 hour
* The Pythn/polars stack took about 2 hours. Polars is a newer library so it took a bit more time to get the test suites to pass.
* The Python/pyspark stack took about 4 hours. The test suites took about a dozen iterations to fully pass due to local spark cluster setup, which is tricky since PySpark requires a JVM to run.

## Running the code
Refer to the README.md under the 3 implementation directories:
* impl-pandas/README.md
* impl-polars/README.md
* impl-spark/README.md

## All prompts issued to Claude Code
For referenace, the complete list of prompts issued to Clause Code is listed below:

> Create a hpi_fhfa_prd.md file to represent a Product Requirements Document (PRD) using the whitepaper located here: '/Users/duc/projects/claude/hpi-fhfa/hpi_fhfa_whitepaper.pdf'. This is an econometric whitepaper. Use it to extract the relevant equations, variables, and coefficients as functional requirements in the hpi-fhfa.md PRD so I can use this PRD later to generate code (Pandas/Numpy, Polars, or PySpark)                      

> use the '/Users/duc/projects/claude/hpi-fhfa/hpi_fhfa_prd.md' file to generate a plan to implement this product requirements document in code                           │

> save this plan as hpi_fhfa_impl_plan.md file in the current directory so I can user it later

> implement the code using this plan and store all the code for this project under the impl-pandas directory                                                          │

> implement the last 2 steps to create unit and integration tests. Generate sample data as needed

> Run all unit and integration tests to make sure they all pass. If not, make changes to the code iteratively until all the tests passed. Generate a report summarizing the restuls of all the unit tests and integration tests 

> now use the same '/Users/duc/projects/claude/hpi-fhfa/hpi_fhfa_impl_plan.md' but this time implement the code using pandas and polars and put everything under the impl-polars directory, including the python virtual environment. Implement all the steps and make sure all the tests pass. Generate a report summarizing the results of all the unit tests and integration tests.

> all tests need to pass. Iterate until a fix is found for each test                                                                         

> The next implementation is pyspark. Use the '/Users/duc/projects/claude/hpi-fhfa/hpi_fhfa_impl_plan.md' but this time implement the code using pyspark and MLlib. Put everything under the impl-pyspark directory. Implement all the steps and make sure all the tests pass. Generate a report summarizing the results of all the unit tests and integration tests.

> find a way to run locally the 54 tests that require a Spark session

> fix all failed tests

> setup a local test infrastructure so that all tests requiring spark session will run and pass

> fix the remaining test failures and do this iteratively untill all tests pass                                                                         

> perform test infrastructure refinements so that all test will pass. Make sure all tests are passing before stopping

> run all tests again and generate a summary of the test results  

> fix the remaining 3 test failures

> save this test report

> create a README.md file and document in details the following: functional summary of the model/code; how to run/use the model for inference; how to run the all the unit tests and integration tests including setup of scripts, environment variables, etc.

