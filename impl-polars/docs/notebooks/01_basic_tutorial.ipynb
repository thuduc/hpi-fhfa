{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HPI-FHFA Basic Tutorial\\n",
        "\\n",
        "This notebook demonstrates basic usage of the HPI-FHFA library for calculating house price indices using the FHFA methodology.\\n",
        "\\n",
        "## Overview\\n",
        "\\n",
        "The HPI-FHFA library implements the Federal Housing Finance Agency's repeat-sales methodology for calculating house price indices at tract and city levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import required libraries\\n",
        "import polars as pl\\n",
        "import numpy as np\\n",
        "from pathlib import Path\\n",
        "from datetime import date, timedelta\\n",
        "\\n",
        "from hpi_fhfa.processing.pipeline import HPIPipeline\\n",
        "from hpi_fhfa.config.settings import HPIConfig\\n",
        "from hpi_fhfa.validation import HPIValidator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create Sample Data\\n",
        "\\n",
        "Let's create some sample transaction and geographic data for demonstration purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create sample transaction data\\n",
        "np.random.seed(42)\\n",
        "\\n",
        "n_transactions = 5000\\n",
        "n_properties = 1500\\n",
        "\\n",
        "# Generate property IDs with repeat sales\\n",
        "property_weights = np.random.exponential(2, n_properties)\\n",
        "property_weights = property_weights / property_weights.sum()\\n",
        "property_ids = np.random.choice(\\n",
        "    [f'P{i:06d}' for i in range(n_properties)],\\n",
        "    size=n_transactions,\\n",
        "    p=property_weights\\n",
        ")\\n",
        "\\n",
        "# Generate dates over 5 years\\n",
        "start_date = date(2018, 1, 1)\\n",
        "end_date = date(2023, 12, 31)\\n",
        "date_range = (end_date - start_date).days\\n",
        "dates = [start_date + timedelta(days=int(d)) for d in np.random.randint(0, date_range, n_transactions)]\\n",
        "\\n",
        "# Generate prices with appreciation trend\\n",
        "base_price = 350000\\n",
        "years_from_start = [(d - start_date).days / 365.25 for d in dates]\\n",
        "annual_appreciation = 0.05  # 5% annual appreciation\\n",
        "price_trend = [base_price * (1 + annual_appreciation) ** year for year in years_from_start]\\n",
        "price_noise = np.random.lognormal(0, 0.25, n_transactions)\\n",
        "prices = [max(75000, trend * noise) for trend, noise in zip(price_trend, price_noise)]\\n",
        "\\n",
        "# Create transaction DataFrame\\n",
        "transactions = pl.DataFrame({\\n",
        "    'property_id': property_ids,\\n",
        "    'transaction_date': dates,\\n",
        "    'transaction_price': prices,\\n",
        "    'census_tract': np.random.choice([f'T{i:03d}' for i in range(20)], n_transactions),\\n",
        "    'cbsa_code': np.random.choice(['CBSA001', 'CBSA002'], n_transactions),\\n",
        "    'distance_to_cbd': np.random.uniform(1, 30, n_transactions)\\n",
        "})\\n",
        "\\n",
        "print(f'Generated {len(transactions):,} transactions')\\n",
        "print(f'Date range: {transactions[\"transaction_date\"].min()} to {transactions[\"transaction_date\"].max()}')\\n",
        "print(f'Price range: ${transactions[\"transaction_price\"].min():,.0f} to ${transactions[\"transaction_price\"].max():,.0f}')\\n",
        "transactions.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create geographic data\\n",
        "tract_ids = [f'T{i:03d}' for i in range(20)]\\n",
        "cbsa_codes = ['CBSA001', 'CBSA002']\\n",
        "\\n",
        "geographic = pl.DataFrame({\\n",
        "    'tract_id': tract_ids,\\n",
        "    'cbsa_code': np.random.choice(cbsa_codes, 20),\\n",
        "    'centroid_lat': np.random.uniform(33.5, 34.5, 20),\\n",
        "    'centroid_lon': np.random.uniform(-118.5, -117.5, 20),\\n",
        "    'housing_units': np.random.randint(1000, 4000, 20),\\n",
        "    'housing_value': np.random.uniform(800_000_000, 2_500_000_000, 20),\\n",
        "    'college_share': np.random.beta(3, 2, 20),\\n",
        "    'nonwhite_share': np.random.beta(2, 3, 20)\\n",
        "})\\n",
        "\\n",
        "print(f'Generated {len(geographic)} census tracts')\\n",
        "geographic.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Configure the Pipeline\\n",
        "\\n",
        "Set up the HPI calculation pipeline with appropriate parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Save data to temporary files\\n",
        "import tempfile\\n",
        "\\n",
        "temp_dir = Path(tempfile.mkdtemp())\\n",
        "print(f'Using temporary directory: {temp_dir}')\\n",
        "\\n",
        "# Save data files\\n",
        "txn_path = temp_dir / 'transactions.parquet'\\n",
        "geo_path = temp_dir / 'geographic.parquet'\\n",
        "\\n",
        "transactions.write_parquet(txn_path)\\n",
        "geographic.write_parquet(geo_path)\\n",
        "\\n",
        "print('Data files saved successfully')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Configure the HPI pipeline\\n",
        "config = HPIConfig(\\n",
        "    transaction_data_path=txn_path,\\n",
        "    geographic_data_path=geo_path,\\n",
        "    output_path=temp_dir / 'output',\\n",
        "    start_year=2019,\\n",
        "    end_year=2023,\\n",
        "    weight_schemes=['sample', 'value', 'unit'],\\n",
        "    n_jobs=2,\\n",
        "    validate_data=True,\\n",
        "    use_lazy_evaluation=False  # For easier debugging\\n",
        ")\\n",
        "\\n",
        "print('Pipeline configuration:')\\n",
        "print(f'  Years: {config.start_year}-{config.end_year}')\\n",
        "print(f'  Weight schemes: {config.weight_schemes}')\\n",
        "print(f'  Parallel jobs: {config.n_jobs}')\\n",
        "print(f'  Validation enabled: {config.validate_data}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Run the Pipeline\\n",
        "\\n",
        "Execute the HPI calculation pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create and run the pipeline\\n",
        "pipeline = HPIPipeline(config)\\n",
        "\\n",
        "print('Running HPI pipeline...')\\n",
        "results = pipeline.run()\\n",
        "\\n",
        "print('Pipeline completed successfully!')\\n",
        "print(f'Processing time: {results.metadata[\"processing_time\"]:.2f} seconds')\\n",
        "print(f'Transactions processed: {results.metadata[\"n_transactions\"]:,}')\\n",
        "print(f'Repeat sales found: {results.metadata[\"n_repeat_sales\"]:,}')\\n",
        "print(f'Filtered sales: {results.metadata[\"n_filtered_sales\"]:,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Analyze Results\\n",
        "\\n",
        "Explore the calculated house price indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Examine tract-level indices\\n",
        "tract_df = results.tract_indices\\n",
        "\\n",
        "print(f'Tract-level indices: {len(tract_df):,} records')\\n",
        "if not tract_df.is_empty():\\n",
        "    print(f'Tracts covered: {tract_df[\"tract_id\"].n_unique()}')\\n",
        "    print(f'Years covered: {tract_df[\"year\"].n_unique()}')\\n",
        "    \\n",
        "    # Show sample data\\n",
        "    print('\\\\nSample tract indices:')\\n",
        "    display(tract_df.head(10))\\n",
        "else:\\n",
        "    print('No tract indices generated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Examine city-level indices\\n",
        "print('City-level indices by weight scheme:')\\n",
        "\\n",
        "for scheme, city_df in results.city_indices.items():\\n",
        "    print(f'\\\\n{scheme.title()} weights:')\\n",
        "    \\n",
        "    if not city_df.is_empty():\\n",
        "        print(f'  Records: {len(city_df)}')\\n",
        "        print(f'  CBSAs covered: {city_df[\"cbsa_code\"].n_unique()}')\\n",
        "        print(f'  Years covered: {city_df[\"year\"].n_unique()}')\\n",
        "        \\n",
        "        # Calculate average appreciation\\n",
        "        appreciation_data = city_df.filter(pl.col('appreciation_rate').is_not_null())\\n",
        "        if len(appreciation_data) > 0:\\n",
        "            avg_appreciation = appreciation_data['appreciation_rate'].mean()\\n",
        "            print(f'  Average appreciation: {avg_appreciation:.2f}%')\\n",
        "        \\n",
        "        # Show sample data\\n",
        "        display(city_df.head())\\n",
        "    else:\\n",
        "        print('  No data generated')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Validate Results\\n",
        "\\n",
        "Run validation checks on the calculated indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Validate the results\\n",
        "validator = HPIValidator(tolerance=0.001)  # 0.1% tolerance\\n",
        "\\n",
        "validation_results = validator.validate_all(\\n",
        "    results.tract_indices,\\n",
        "    results.city_indices\\n",
        ")\\n",
        "\\n",
        "print('Validation completed')\\n",
        "print(f'Total validation tests: {len(validation_results)}')\\n",
        "\\n",
        "# Show validation summary\\n",
        "passed = sum(1 for r in validation_results if r.passed)\\n",
        "failed = len(validation_results) - passed\\n",
        "\\n",
        "print(f'Passed: {passed}')\\n",
        "print(f'Failed: {failed}')\\n",
        "print(f'Success rate: {passed/len(validation_results)*100:.1f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Show detailed validation report\\n",
        "print('Detailed Validation Report:')\\n",
        "print('=' * 50)\\n",
        "print(validator.get_summary_report())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Visualize Results (Optional)\\n",
        "\\n",
        "Create basic visualizations of the house price indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Optional: Create visualizations if matplotlib is available\\n",
        "try:\\n",
        "    import matplotlib.pyplot as plt\\n",
        "    \\n",
        "    # Plot tract-level appreciation over time\\n",
        "    if not tract_df.is_empty():\\n",
        "        appreciation_data = tract_df.filter(\\n",
        "            pl.col('appreciation_rate').is_not_null()\\n",
        "        )\\n",
        "        \\n",
        "        if len(appreciation_data) > 0:\\n",
        "            # Calculate average appreciation by year\\n",
        "            yearly_appreciation = (\\n",
        "                appreciation_data\\n",
        "                .group_by('year')\\n",
        "                .agg(pl.col('appreciation_rate').mean().alias('avg_appreciation'))\\n",
        "                .sort('year')\\n",
        "            )\\n",
        "            \\n",
        "            plt.figure(figsize=(10, 6))\\n",
        "            \\n",
        "            years = yearly_appreciation['year'].to_list()\\n",
        "            appreciations = yearly_appreciation['avg_appreciation'].to_list()\\n",
        "            \\n",
        "            plt.plot(years, appreciations, marker='o', linewidth=2, markersize=8)\\n",
        "            plt.title('Average Tract-Level House Price Appreciation', fontsize=14, fontweight='bold')\\n",
        "            plt.xlabel('Year', fontsize=12)\\n",
        "            plt.ylabel('Appreciation Rate (%)', fontsize=12)\\n",
        "            plt.grid(True, alpha=0.3)\\n",
        "            plt.tight_layout()\\n",
        "            plt.show()\\n",
        "            \\n",
        "            print('Tract-level appreciation chart created')\\n",
        "        else:\\n",
        "            print('No appreciation data available for charting')\\n",
        "    \\n",
        "except ImportError:\\n",
        "    print('Matplotlib not available - skipping visualizations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\\n",
        "\\n",
        "This tutorial demonstrated the basic usage of the HPI-FHFA library:\\n",
        "\\n",
        "1. **Data Preparation**: Created sample transaction and geographic data\\n",
        "2. **Pipeline Configuration**: Set up the HPI calculation parameters\\n",
        "3. **Execution**: Ran the complete HPI calculation pipeline\\n",
        "4. **Analysis**: Examined tract and city-level indices\\n",
        "5. **Validation**: Verified result quality and accuracy\\n",
        "\\n",
        "For more advanced usage, see the other example notebooks and documentation.\\n",
        "\\n",
        "### Next Steps:\\n",
        "\\n",
        "- Try different weight schemes\\n",
        "- Experiment with different time periods\\n",
        "- Use your own real estate transaction data\\n",
        "- Explore performance optimization options\\n",
        "- Compare results with reference implementations"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}